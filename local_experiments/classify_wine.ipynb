{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-12T13:04:15.338941100Z",
     "start_time": "2023-11-12T13:04:12.781149500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "## PREPARE DATA ##\n",
    "wine_df = pd.read_csv(\"../winequality.csv\")\n",
    "\n",
    "# Fill missing data with either random data or a category corresponding to \"Unknown\"\n",
    "for column in wine_df.columns:\n",
    "    if wine_df[column].isna().any() and pd.api.types.is_numeric_dtype(wine_df[column]):\n",
    "        wine_df.loc[wine_df[column].isna(), column] = [i for i in np.random.choice(range(round(wine_df[column].min()), round(wine_df[column]. max())), wine_df[column].isna().sum())]\n",
    "    elif wine_df[column].isna().any() and (pd.api.types.is_object_dtype(wine_df[column]) or pd.api.types.is_categorical_dtype(wine_df[column])):\n",
    "        wine_df[column].fillna(\"Unknown\")\n",
    "\n",
    "# One-hot encode wine type\n",
    "for column in wine_df.columns:\n",
    "    if pd.api.types.is_categorical_dtype(wine_df[column]) or pd.api.types.is_object_dtype(wine_df[column]):\n",
    "        one_hot = pd.get_dummies(wine_df[column], prefix=column)\n",
    "        wine_df = wine_df.drop(column, axis = 1)\n",
    "        wine_df = wine_df.join(one_hot)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T13:04:15.407661700Z",
     "start_time": "2023-11-12T13:04:15.331426400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0               7.0             0.270         0.36            20.7      0.045   \n1               6.3             0.300         0.34             1.6      0.049   \n2               8.1             0.280         0.40             6.9      0.050   \n3               7.2             0.230         0.32             8.5      0.058   \n4               7.2             0.230         0.32             8.5      0.058   \n...             ...               ...          ...             ...        ...   \n6492            6.2             0.600         0.08             2.0      0.090   \n6493            5.9             0.550         0.10             2.2      0.062   \n6494            6.3             0.510         0.13             2.3      0.076   \n6495            5.9             0.645         0.12             2.0      0.075   \n6496            6.0             0.310         0.47             3.6      0.067   \n\n      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                    45.0                 170.0  1.00100  3.00       0.45   \n1                    14.0                 132.0  0.99400  3.30       0.49   \n2                    30.0                  97.0  0.99510  3.26       0.44   \n3                    47.0                 186.0  0.99560  3.19       0.40   \n4                    47.0                 186.0  0.99560  3.19       0.40   \n...                   ...                   ...      ...   ...        ...   \n6492                 32.0                  44.0  0.99490  3.45       0.58   \n6493                 39.0                  51.0  0.99512  3.52       1.00   \n6494                 29.0                  40.0  0.99574  3.42       0.75   \n6495                 32.0                  44.0  0.99547  3.57       0.71   \n6496                 18.0                  42.0  0.99549  3.39       0.66   \n\n      alcohol  quality  type_red  type_white  \n0         8.8        6         0           1  \n1         9.5        6         0           1  \n2        10.1        6         0           1  \n3         9.9        6         0           1  \n4         9.9        6         0           1  \n...       ...      ...       ...         ...  \n6492     10.5        5         1           0  \n6493     11.2        6         1           0  \n6494     11.0        6         1           0  \n6495     10.2        5         1           0  \n6496     11.0        6         1           0  \n\n[6497 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n      <th>type_red</th>\n      <th>type_white</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.0</td>\n      <td>0.270</td>\n      <td>0.36</td>\n      <td>20.7</td>\n      <td>0.045</td>\n      <td>45.0</td>\n      <td>170.0</td>\n      <td>1.00100</td>\n      <td>3.00</td>\n      <td>0.45</td>\n      <td>8.8</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.3</td>\n      <td>0.300</td>\n      <td>0.34</td>\n      <td>1.6</td>\n      <td>0.049</td>\n      <td>14.0</td>\n      <td>132.0</td>\n      <td>0.99400</td>\n      <td>3.30</td>\n      <td>0.49</td>\n      <td>9.5</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.1</td>\n      <td>0.280</td>\n      <td>0.40</td>\n      <td>6.9</td>\n      <td>0.050</td>\n      <td>30.0</td>\n      <td>97.0</td>\n      <td>0.99510</td>\n      <td>3.26</td>\n      <td>0.44</td>\n      <td>10.1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.2</td>\n      <td>0.230</td>\n      <td>0.32</td>\n      <td>8.5</td>\n      <td>0.058</td>\n      <td>47.0</td>\n      <td>186.0</td>\n      <td>0.99560</td>\n      <td>3.19</td>\n      <td>0.40</td>\n      <td>9.9</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.2</td>\n      <td>0.230</td>\n      <td>0.32</td>\n      <td>8.5</td>\n      <td>0.058</td>\n      <td>47.0</td>\n      <td>186.0</td>\n      <td>0.99560</td>\n      <td>3.19</td>\n      <td>0.40</td>\n      <td>9.9</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6492</th>\n      <td>6.2</td>\n      <td>0.600</td>\n      <td>0.08</td>\n      <td>2.0</td>\n      <td>0.090</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99490</td>\n      <td>3.45</td>\n      <td>0.58</td>\n      <td>10.5</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6493</th>\n      <td>5.9</td>\n      <td>0.550</td>\n      <td>0.10</td>\n      <td>2.2</td>\n      <td>0.062</td>\n      <td>39.0</td>\n      <td>51.0</td>\n      <td>0.99512</td>\n      <td>3.52</td>\n      <td>1.00</td>\n      <td>11.2</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6494</th>\n      <td>6.3</td>\n      <td>0.510</td>\n      <td>0.13</td>\n      <td>2.3</td>\n      <td>0.076</td>\n      <td>29.0</td>\n      <td>40.0</td>\n      <td>0.99574</td>\n      <td>3.42</td>\n      <td>0.75</td>\n      <td>11.0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6495</th>\n      <td>5.9</td>\n      <td>0.645</td>\n      <td>0.12</td>\n      <td>2.0</td>\n      <td>0.075</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99547</td>\n      <td>3.57</td>\n      <td>0.71</td>\n      <td>10.2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6496</th>\n      <td>6.0</td>\n      <td>0.310</td>\n      <td>0.47</td>\n      <td>3.6</td>\n      <td>0.067</td>\n      <td>18.0</td>\n      <td>42.0</td>\n      <td>0.99549</td>\n      <td>3.39</td>\n      <td>0.66</td>\n      <td>11.0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6497 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T13:04:15.458476400Z",
     "start_time": "2023-11-12T13:04:15.407661700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def run_clf(X_train, X_test, y_train, y_test):\n",
    "    ## XGBOOST ##\n",
    "    # Initialize the XGBoost classifier\n",
    "    xgb_clf = xgb.XGBClassifier(objective='multi:softprob', eval_metric='mlogloss',n_estimators=1000)\n",
    "\n",
    "    # Train the classifier\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # Predictions on the test set\n",
    "    xgb_y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
    "    print(\"XGBoost accuracy:\", xgb_accuracy)\n",
    "\n",
    "\n",
    "    ## RANDOM FOREST ##\n",
    "    # Initialize the RF classifier\n",
    "    rf_clf = RandomForestClassifier()\n",
    "\n",
    "    # Train the classifier\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    rf_y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "    print(\"RF accuracy:\", rf_accuracy)\n",
    "\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T13:05:37.635403100Z",
     "start_time": "2023-11-12T13:05:37.609914300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [],
   "source": [
    "def run_bin_clf(X_train, X_test, y_train, y_test):\n",
    "    ## XGBOOST ##\n",
    "    # Initialize the XGBoost classifier\n",
    "    xgb_clf = xgb.XGBClassifier(n_estimators = 1000)\n",
    "\n",
    "    # Train the classifier\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # Predictions on the test set\n",
    "    xgb_y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
    "    print(\"XGBoost accuracy:\", xgb_accuracy)\n",
    "\n",
    "\n",
    "    ## RANDOM FOREST ##\n",
    "    # Initialize the RF classifier\n",
    "    rf_clf = RandomForestClassifier()\n",
    "\n",
    "    # Train the classifier\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    rf_y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "    print(\"RF accuracy:\", rf_accuracy)\n",
    "\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T15:41:57.825578500Z",
     "start_time": "2023-11-11T15:41:57.786010Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracies without dropping features:\n",
      "XGBoost accuracy: 0.6630769230769231\n",
      "RF accuracy: 0.6876923076923077\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## CLASSIFY WITHOUT REMOVING DATA FEATURES ##\n",
    "X = wine_df.drop(\"quality\", axis=1)\n",
    "y = wine_df[\"quality\"]\n",
    "y = y - 3 # remap labels from 3-9 to 0-6\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "print()\n",
    "print(\"Accuracies without dropping features:\")\n",
    "run_clf(X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T15:27:15.640746900Z",
     "start_time": "2023-11-11T15:27:11.174507400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [],
   "source": [
    "## CLASSIFY with binary categories"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T15:27:21.442200900Z",
     "start_time": "2023-11-11T15:27:21.428565900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [],
   "source": [
    "#define wine class [1 = 'Good Quality', 0 = 'Bad Quality']\n",
    "wine_df['def_quality'] = [0 if x < 7 else 1 for x in wine_df['quality']]# Separate feature variables and target variable\n",
    "X_binary = wine_df.drop(['quality','def_quality'], axis = 1)\n",
    "y_binary = wine_df['def_quality']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T15:27:49.252171Z",
     "start_time": "2023-11-11T15:27:49.234975800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "data": {
      "text/plain": "0    5220\n1    1277\nName: def_quality, dtype: int64"
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_binary.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T15:27:49.775892800Z",
     "start_time": "2023-11-11T15:27:49.739435Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracies without dropping features and binary classification:\n",
      "XGBoost accuracy: 0.88\n",
      "RF accuracy: 0.8930769230769231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, stratify=y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "print()\n",
    "print(\"Accuracies without dropping features and binary classification:\")\n",
    "run_bin_clf(X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T15:27:52.137268400Z",
     "start_time": "2023-11-11T15:27:50.756977Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "## Classification with three categories\n",
    "#define wine class [2 = 'Good Quality', 1 = \"Mediocre Quality\", 0 = 'Bad Quality']\n",
    "wine_df['def_quality'] = [0 if x < 4  else 1 if x==4 else 2 if x==5 else 3 if x <8  else 4 for x in wine_df['quality']]# Separate feature variables and target variable\n",
    "X_triad = wine_df.drop(['quality','def_quality'], axis = 1)\n",
    "y_triad = wine_df['def_quality']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T13:25:23.824353100Z",
     "start_time": "2023-11-12T13:25:23.760094900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "3    3915\n2    2138\n1     216\n4     198\n0      30\nName: def_quality, dtype: int64"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_triad.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T13:25:24.484880100Z",
     "start_time": "2023-11-12T13:25:24.460830600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracies without dropping features and three class classification:\n",
      "XGBoost accuracy: 0.7815384615384615\n",
      "RF accuracy: 0.7984615384615384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_triad, y_triad, stratify=y_triad, test_size=0.2, random_state=42)\n",
    "\n",
    "print()\n",
    "print(\"Accuracies without dropping features and five class classification:\")\n",
    "run_clf(X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T13:25:35.787845600Z",
     "start_time": "2023-11-12T13:25:28.666422900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "                      fixed acidity  volatile acidity  citric acid  \\\nfixed acidity                   NaN          0.215678     0.314308   \nvolatile acidity                NaN               NaN     0.371319   \ncitric acid                     NaN               NaN          NaN   \nresidual sugar                  NaN               NaN          NaN   \nchlorides                       NaN               NaN          NaN   \nfree sulfur dioxide             NaN               NaN          NaN   \ntotal sulfur dioxide            NaN               NaN          NaN   \ndensity                         NaN               NaN          NaN   \npH                              NaN               NaN          NaN   \nsulphates                       NaN               NaN          NaN   \nalcohol                         NaN               NaN          NaN   \ntype_red                        NaN               NaN          NaN   \ntype_white                      NaN               NaN          NaN   \ndef_quality                     NaN               NaN          NaN   \n\n                      residual sugar  chlorides  free sulfur dioxide  \\\nfixed acidity               0.113306   0.294156             0.281460   \nvolatile acidity            0.197261   0.373866             0.351053   \ncitric acid                 0.142294   0.038801             0.133864   \nresidual sugar                   NaN   0.129194             0.403910   \nchlorides                        NaN        NaN             0.194886   \nfree sulfur dioxide              NaN        NaN                  NaN   \ntotal sulfur dioxide             NaN        NaN                  NaN   \ndensity                          NaN        NaN                  NaN   \npH                               NaN        NaN                  NaN   \nsulphates                        NaN        NaN                  NaN   \nalcohol                          NaN        NaN                  NaN   \ntype_red                         NaN        NaN                  NaN   \ntype_white                       NaN        NaN                  NaN   \ndef_quality                      NaN        NaN                  NaN   \n\n                      total sulfur dioxide   density        pH  sulphates  \\\nfixed acidity                     0.325798  0.452628  0.249073   0.298446   \nvolatile acidity                  0.412788  0.268338  0.258464   0.221856   \ncitric acid                       0.195052  0.096903  0.325818   0.057967   \nresidual sugar                    0.494985  0.549867  0.264255   0.184349   \nchlorides                         0.279562  0.362519  0.045527   0.392981   \nfree sulfur dioxide               0.720934  0.025717  0.144851   0.186899   \ntotal sulfur dioxide                   NaN  0.032395  0.236932   0.273584   \ndensity                                NaN       NaN  0.012061   0.258226   \npH                                     NaN       NaN       NaN   0.190663   \nsulphates                              NaN       NaN       NaN        NaN   \nalcohol                                NaN       NaN       NaN        NaN   \ntype_red                               NaN       NaN       NaN        NaN   \ntype_white                             NaN       NaN       NaN        NaN   \ndef_quality                            NaN       NaN       NaN        NaN   \n\n                       alcohol  type_red  type_white  def_quality  \nfixed acidity         0.094184  0.482639    0.482639     0.074083  \nvolatile acidity      0.039486  0.647138    0.647138     0.271438  \ncitric acid           0.011327  0.185694    0.185694     0.084459  \nresidual sugar        0.359684  0.348519    0.348519     0.009538  \nchlorides             0.256871  0.512675    0.512675     0.176085  \nfree sulfur dioxide   0.179838  0.471644    0.471644     0.067910  \ntotal sulfur dioxide  0.265740  0.700357    0.700357     0.025259  \ndensity               0.686745  0.390645    0.390645     0.250895  \npH                    0.121035  0.328199    0.328199     0.008584  \nsulphates             0.003676  0.484412    0.484412     0.034334  \nalcohol                    NaN  0.032970    0.032970     0.370796  \ntype_red                   NaN       NaN    1.000000     0.110400  \ntype_white                 NaN       NaN         NaN     0.110400  \ndef_quality                NaN       NaN         NaN          NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>type_red</th>\n      <th>type_white</th>\n      <th>def_quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>fixed acidity</th>\n      <td>NaN</td>\n      <td>0.215678</td>\n      <td>0.314308</td>\n      <td>0.113306</td>\n      <td>0.294156</td>\n      <td>0.281460</td>\n      <td>0.325798</td>\n      <td>0.452628</td>\n      <td>0.249073</td>\n      <td>0.298446</td>\n      <td>0.094184</td>\n      <td>0.482639</td>\n      <td>0.482639</td>\n      <td>0.074083</td>\n    </tr>\n    <tr>\n      <th>volatile acidity</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.371319</td>\n      <td>0.197261</td>\n      <td>0.373866</td>\n      <td>0.351053</td>\n      <td>0.412788</td>\n      <td>0.268338</td>\n      <td>0.258464</td>\n      <td>0.221856</td>\n      <td>0.039486</td>\n      <td>0.647138</td>\n      <td>0.647138</td>\n      <td>0.271438</td>\n    </tr>\n    <tr>\n      <th>citric acid</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.142294</td>\n      <td>0.038801</td>\n      <td>0.133864</td>\n      <td>0.195052</td>\n      <td>0.096903</td>\n      <td>0.325818</td>\n      <td>0.057967</td>\n      <td>0.011327</td>\n      <td>0.185694</td>\n      <td>0.185694</td>\n      <td>0.084459</td>\n    </tr>\n    <tr>\n      <th>residual sugar</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.129194</td>\n      <td>0.403910</td>\n      <td>0.494985</td>\n      <td>0.549867</td>\n      <td>0.264255</td>\n      <td>0.184349</td>\n      <td>0.359684</td>\n      <td>0.348519</td>\n      <td>0.348519</td>\n      <td>0.009538</td>\n    </tr>\n    <tr>\n      <th>chlorides</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.194886</td>\n      <td>0.279562</td>\n      <td>0.362519</td>\n      <td>0.045527</td>\n      <td>0.392981</td>\n      <td>0.256871</td>\n      <td>0.512675</td>\n      <td>0.512675</td>\n      <td>0.176085</td>\n    </tr>\n    <tr>\n      <th>free sulfur dioxide</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.720934</td>\n      <td>0.025717</td>\n      <td>0.144851</td>\n      <td>0.186899</td>\n      <td>0.179838</td>\n      <td>0.471644</td>\n      <td>0.471644</td>\n      <td>0.067910</td>\n    </tr>\n    <tr>\n      <th>total sulfur dioxide</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.032395</td>\n      <td>0.236932</td>\n      <td>0.273584</td>\n      <td>0.265740</td>\n      <td>0.700357</td>\n      <td>0.700357</td>\n      <td>0.025259</td>\n    </tr>\n    <tr>\n      <th>density</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.012061</td>\n      <td>0.258226</td>\n      <td>0.686745</td>\n      <td>0.390645</td>\n      <td>0.390645</td>\n      <td>0.250895</td>\n    </tr>\n    <tr>\n      <th>pH</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.190663</td>\n      <td>0.121035</td>\n      <td>0.328199</td>\n      <td>0.328199</td>\n      <td>0.008584</td>\n    </tr>\n    <tr>\n      <th>sulphates</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.003676</td>\n      <td>0.484412</td>\n      <td>0.484412</td>\n      <td>0.034334</td>\n    </tr>\n    <tr>\n      <th>alcohol</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.032970</td>\n      <td>0.032970</td>\n      <td>0.370796</td>\n    </tr>\n    <tr>\n      <th>type_red</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>0.110400</td>\n    </tr>\n    <tr>\n      <th>type_white</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.110400</td>\n    </tr>\n    <tr>\n      <th>def_quality</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features to exclude['total sulfur dioxide', 'type_white']\n",
      "features to be kept ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality', 'type_red', 'def_quality']\n"
     ]
    }
   ],
   "source": [
    "## FEATURE SELECTION ##\n",
    "features = wine_df.loc[:, wine_df.columns != 'quality']\n",
    "cor = abs(features.corr())\n",
    "feature_cor_upper = cor.where(np.triu(np.ones(cor.shape), k=1).astype(bool))\n",
    "display(feature_cor_upper)\n",
    "features_to_exclude = [column for column in feature_cor_upper.columns if any(feature_cor_upper[column] > 0.71)]\n",
    "print(f\"features to exclude{features_to_exclude}\")\n",
    "# Find features to be kept\n",
    "features_to_be_kept = [feature for feature in wine_df.columns if feature not in features_to_exclude]\n",
    "print(f\"features to be kept {features_to_be_kept}\")\n",
    "# Drop features: drop all features that show a low correlation with the target variable and that are highly intercorrelated\n",
    "for column in wine_df.columns:\n",
    "    if column not in features_to_be_kept:\n",
    "        wine_df.drop(column, axis=1, inplace=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T14:27:04.444082300Z",
     "start_time": "2023-11-12T14:27:04.307367800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "## Classification with three categories\n",
    "#define wine class [2 = 'Good Quality', 1 = \"Mediocre Quality\", 0 = 'Bad Quality']\n",
    "wine_df['def_quality'] = wine_df['def_quality'] = [0 if x < 4  else 1 if x==4 else 2 if x==5 else 3 if x <8  else 4 for x in wine_df['quality']]# Separate feature variables and target variable\n",
    "X_five = wine_df.drop(['quality','def_quality'], axis = 1)\n",
    "y_five = wine_df['def_quality']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T14:30:40.226784400Z",
     "start_time": "2023-11-12T14:30:40.191997100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "3    3915\n2    2138\n1     216\n4     198\n0      30\nName: def_quality, dtype: int64"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_five.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T14:30:47.225322800Z",
     "start_time": "2023-11-12T14:30:47.203426800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracies with feature subset and three class classification:\n",
      "XGBoost accuracy: 0.7815384615384615\n",
      "RF accuracy: 0.7961538461538461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "X_train_five, X_test_five, y_train_five, y_test_five = train_test_split(X_five, y_five, stratify=y_five, test_size=0.2, random_state=42)\n",
    "\n",
    "#print()\n",
    "#print(\"Accuracies with feature subset and three class classification:\")\n",
    "#run_clf(X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T14:30:53.007789100Z",
     "start_time": "2023-11-12T14:30:48.876470800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best set of hyperparameters:  {'learning_rate': 0.1, 'max_depth': 7, 'subsample': 0.7}\n",
      "Best score:  0.7550523802472793\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameter tuning for XGBoost\n",
    "# https://medium.com/@rithpansanga/optimizing-xgboost-a-guide-to-hyperparameter-tuning-77b6e48e289d\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'subsample': [0.5, 0.7, 1]\n",
    "}\n",
    "\n",
    "# Create the XGBoost model object\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train_five, y_train_five)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T14:45:56.218643800Z",
     "start_time": "2023-11-12T14:44:00.398288100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\xgboost\\core.py:726: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy: 0.7753846153846153\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(grid_search.best_params_)\n",
    "\n",
    "# Train the classifier\n",
    "xgb_clf.fit(X_train_five, y_train_five)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predictions on the test set\n",
    "xgb_y_pred = xgb_clf.predict(X_test_five)\n",
    "\n",
    "# Calculate the accuracy\n",
    "xgb_accuracy = accuracy_score(y_test_five, xgb_y_pred)\n",
    "print(\"XGBoost accuracy:\", xgb_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T14:46:01.126944500Z",
     "start_time": "2023-11-12T14:46:00.202649800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best set of hyperparameters:  {'max_depth': 10, 'max_features': 'auto'}\n",
      "Best score:  0.7385044791589547\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameter tuning for RandomForest\n",
    "# https://medium.com/@rithpansanga/optimizing-xgboost-a-guide-to-hyperparameter-tuning-77b6e48e289d\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [3, 5, 7, 10]\n",
    "}\n",
    "\n",
    "## RANDOM FOREST ##\n",
    "# Initialize the RF classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(rf_clf, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train_five, y_train_five)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T15:36:29.219652700Z",
     "start_time": "2023-11-12T15:36:03.780861200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marie\\Documents\\KTH\\Semester_3\\Period_2\\ID2223\\Assignment_1\\id2223-lab1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF accuracy: 0.7507692307692307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## RANDOM FOREST ##\n",
    "# Initialize the RF classifier\n",
    "rf_clf = RandomForestClassifier(max_depth=grid_search.best_params_['max_depth'], max_features=grid_search.best_params_['max_features'])\n",
    "\n",
    "# Train the classifier\n",
    "rf_clf.fit(X_train_five, y_train_five)\n",
    "\n",
    "# Predictions on the test set\n",
    "rf_y_pred = rf_clf.predict(X_test_five)\n",
    "\n",
    "# Calculate the accuracy\n",
    "rf_accuracy = accuracy_score(y_test_five, rf_y_pred)\n",
    "print(\"RF accuracy:\", rf_accuracy)\n",
    "\n",
    "print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T15:43:50.435375Z",
     "start_time": "2023-11-12T15:43:49.916732300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies with feature subset:\n",
      "XGBoost accuracy: 0.6276923076923077\n",
      "RF accuracy: 0.6584615384615384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## CLASSIFY AFTER FEATURE SELECTION ##\n",
    "X = wine_df.drop(\"quality\", axis=1)\n",
    "y = wine_df[\"quality\"]\n",
    "y = y - 3 # remap labels from 3-9 to 0-6\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Accuracies with feature subset:\")\n",
    "run_clf(X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T15:42:12.212261500Z",
     "start_time": "2023-11-11T15:42:08.270243700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Selection with Most Important Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "## CLASSIFY with binary categories"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T15:42:13.313257Z",
     "start_time": "2023-11-11T15:42:13.299255100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [],
   "source": [
    "#define wine class [1 = 'Good Quality', 0 = 'Bad Quality']\n",
    "wine_df['def_quality'] = [0 if x < 7 else 1 for x in wine_df['quality']]# Separate feature variables and target variable\n",
    "X_binary = wine_df.drop(['quality','def_quality'], axis = 1)\n",
    "y_binary = wine_df['def_quality']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T15:42:27.195863500Z",
     "start_time": "2023-11-11T15:42:27.167367100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [
    {
     "data": {
      "text/plain": "0    5220\n1    1277\nName: def_quality, dtype: int64"
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_binary.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T15:42:27.612748Z",
     "start_time": "2023-11-11T15:42:27.599748500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracies with feature subset and binary classification:\n",
      "XGBoost accuracy: 0.8615384615384616\n",
      "RF accuracy: 0.8746153846153846\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, stratify=y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "print()\n",
    "print(\"Accuracies with feature subset and binary classification:\")\n",
    "run_bin_clf(X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T15:42:29.613373400Z",
     "start_time": "2023-11-11T15:42:28.367627500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "3    567\n2    428\n4    216\n1     43\n5     39\n0      6\n6      1\nName: quality, dtype: int64"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## split quality into good vs\n",
    "y_test.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T13:51:22.066021400Z",
     "start_time": "2023-11-11T13:51:22.041787Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [
    {
     "data": {
      "text/plain": "fixed acidity       0.078026\ncitric acid         0.085780\ntype_white          0.119323\ntype_red            0.119323\nchlorides           0.200278\nvolatile acidity    0.264573\ndensity             0.305858\nalcohol             0.444319\nquality             1.000000\nName: quality, dtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of most important featuers: 8\n"
     ]
    }
   ],
   "source": [
    "# Checking for correlation between the important features\n",
    "# If features are highly intercorrelated, we should only keep one and drop the other\n",
    "# we should probably drop either red or white and maybe density since it is highly correlated with alcohol\n",
    "\n",
    "# Correlation with target variable quality\n",
    "cor = wine_df.corr()\n",
    "cor_quality = abs(cor[\"quality\"])\n",
    "\n",
    "threshold = 0.075\n",
    "\n",
    "# Selecting only features with correlation coefficient > threshold\n",
    "important_features = cor_quality[cor_quality > threshold].sort_values()\n",
    "display(important_features)\n",
    "print(f\"Number of most important featuers: {len(important_features) - 1}\")\n",
    "\n",
    "feature_cor = wine_df[list(important_features.iloc[:-1].index)].corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "feature_cor_upper = feature_cor.where(np.triu(np.ones(feature_cor.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation greater than 0.95\n",
    "features_to_exclude = [column for column in feature_cor_upper.columns if any(feature_cor_upper[column] > 0.95)]\n",
    "\n",
    "# Find features to be kept\n",
    "features_to_be_kept = [feature for feature in important_features.index.to_list() if feature not in features_to_exclude]\n",
    "\n",
    "# Drop features: drop all features that show a low correlation with the target variable and that are highly intercorrelated\n",
    "for column in wine_df.columns:\n",
    "    if column not in features_to_be_kept:\n",
    "        wine_df.drop(column, axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T15:42:07.041701Z",
     "start_time": "2023-11-11T15:42:07.014237600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
